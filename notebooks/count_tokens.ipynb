{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "import numpy as np\n",
    "import tiktoken\n",
    "from datasets import Dataset, concatenate_datasets, load_dataset\n",
    "from pandas import Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dialogue(group):\n",
    "    messages = [[{\"role\": \"user\", \"content\": u}, {\"role\": \"assistant\", \"content\": a}] for u, a in zip(group[\"user\"], group[\"assistant\"])]\n",
    "    return Series({\"messages\": list(chain(*messages))})\n",
    "\n",
    "\n",
    "def build_messages(example):\n",
    "    question = [{\"role\": \"user\", \"content\": example[\"question\"]}]\n",
    "    chosen = [{\"role\": \"assistant\", \"content\": example[\"personalized_answer\"]}]\n",
    "    return {\"messages\": question + chosen}\n",
    "\n",
    "\n",
    "def count_tokens(example, tokenizer, feature):\n",
    "    tokens = 0\n",
    "    for message in example[feature]:\n",
    "        tokens += 3\n",
    "        for k, v in message.items():\n",
    "            tokens += len(tokenizer.encode(v))\n",
    "            if k == \"name\":\n",
    "                tokens += 1\n",
    "    tokens += 3  # every reply is primed with <|start|>assistant<|message|>\n",
    "    return {f\"{feature}_tokens\": tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogue_dict = load_dataset(\"arranonymsub/HiCUPID\", name=\"dialogue\")\n",
    "dialogue = concatenate_datasets(list(dialogue_dict.values()))\n",
    "by_type = Dataset.from_pandas(dialogue.to_pandas().groupby([\"user_id\", \"type\"]).apply(build_dialogue, include_groups=False))\n",
    "by_user = Dataset.from_pandas(dialogue.to_pandas().groupby(\"user_id\").apply(build_dialogue, include_groups=False))\n",
    "qa_dict = load_dataset(\"arranonymsub/HiCUPID\", name=\"qa\")\n",
    "qa = concatenate_datasets(list(qa_dict.values()))\n",
    "qa = qa.map(build_messages, num_proc=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c50849ff406b417e987e276a5eed0547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/4500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42848fcc13274ea1a944ffeae2e50ddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=16):   0%|          | 0/4500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0578c715efed4b40b07790dbb0534b38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=16):   0%|          | 0/4500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "facc65aa632846b99e62b142a150af5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=16):   0%|          | 0/4500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "177cf08f36aa4a01bcb966aa48520056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialogue Length (Persona): 15962.3 +- 538.1\n",
      "Dialogue Length (Profile): 329.0 +- 31.4\n",
      "Dialogue Length (Schedule): 970.9 +- 50.7\n",
      "Dialogue Length (Whole): 17256.3 +- 543.7\n",
      "QA Length: 57.3 +- 17.9\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.encoding_for_model(\"gpt-2\")\n",
    "by_type = by_type.map(count_tokens, fn_kwargs={\"tokenizer\": tokenizer, \"feature\": \"messages\"}, num_proc=16)\n",
    "persona = by_type.filter(lambda x: x[\"type\"] == \"persona\", num_proc=16)\n",
    "profile = by_type.filter(lambda x: x[\"type\"] == \"profile\", num_proc=16)\n",
    "schedule = by_type.filter(lambda x: x[\"type\"] == \"schedule\", num_proc=16)\n",
    "by_user = by_user.map(count_tokens, fn_kwargs={\"tokenizer\": tokenizer, \"feature\": \"messages\"}, num_proc=16)\n",
    "qa = qa.map(count_tokens, fn_kwargs={\"tokenizer\": tokenizer, \"feature\": \"messages\"}, num_proc=16)\n",
    "\n",
    "print(f\"Dialogue Length (Persona): {np.mean(persona['messages_tokens']):.1f} +- {np.std(persona['messages_tokens'], ddof=1):.1f}\")\n",
    "print(f\"Dialogue Length (Profile): {np.mean(profile['messages_tokens']):.1f} +- {np.std(profile['messages_tokens'], ddof=1):.1f}\")\n",
    "print(f\"Dialogue Length (Schedule): {np.mean(schedule['messages_tokens']):.1f} +- {np.std(schedule['messages_tokens'], ddof=1):.1f}\")\n",
    "print(f\"Dialogue Length (Whole): {np.mean(by_user['messages_tokens']):.1f} +- {np.std(by_user['messages_tokens'], ddof=1):.1f}\")\n",
    "print(f\"QA Length: {np.mean(qa['messages_tokens']):.1f} +- {np.std(qa['messages_tokens'], ddof=1):.1f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cupid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
